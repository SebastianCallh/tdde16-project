
  :PROPERTIES:
  :header-args: :eval never-export
  :header-args:bash: :exports code
  :header-args:elisp: :exports code
  :header-args:ipython: :exports both
  :END:

#+BEGIN_SRC bash :dir ~/.venv/ :results drawer
  pwd
  virtualenv -p python3 tdde16
#+END_SRC

#+BEGIN_SRC elisp :results silent
  (pyvenv-activate "~/.venv/tdde16")
#+END_SRC

#+BEGIN_SRC bash :results drawer :async t
  pip install ipython jupyter_client jupyter_console numpy matplotlib pandas sklearn gensim seaborn cython keras
#+END_SRC

* Text Classification Using RNN

  #+begin_src ipython  :results drawer :async t :session s :exports output
    %matplotlib inline
    import pandas as pd
    import numpy as np
    train = pd.read_csv('./toxic/train.csv')
    test = pd.read_csv('./toxic/test.csv')
    truth = pd.read_csv('./toxic/test_labels.csv')
    tags = ['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] 
    train_X = train.comment_text
    train_Y = train[tags]
    test_and_truth = test.merge(truth).query('threat != -1')
    test_X = test_and_truth.comment_text
    test_Y = test_and_truth[tags]
    np.random.seed(1)
  #+end_src

  #+RESULTS:
  :RESULTS:
  # Out[65]:
  #+BEGIN_EXAMPLE
    severe_toxic  obscene  threat  insult  identity_hate
    5              0        0       0       0              0
    7              0        0       0       0              0
    11             0        0       0       0              0
    13             0        0       0       0              0
    14             0        0       0       0              0
  #+END_EXAMPLE
  :END:

** Naive Bayes

   #+BEGIN_SRC ipython :results drawer :async t :session s :async
     from sklearn.naive_bayes import ComplementNB
     from sklearn.feature_extraction.text import CountVectorizer
     from sklearn.pipeline import Pipeline
     from sklearn.metrics import classification_report

     def train_naive_bayes(X, y):
	 pl = Pipeline([
	     ('vect', CountVectorizer()),
	     ('clf', ComplementNB())
	 ])
	 return pl.fit(X, y)

     nbs = [train_naive_bayes(train_X, train_Y[tag]) for tag in tags]

     for nb, tag in zip(nbs, tags):
	 pred = nb.predict(test_X)
	 true = test_and_truth[tag]
	 print('Accuracy:', np.mean(pred == true))
	 print(classification_report(
	    true, pred, target_names=['ok', tag]))
  #+END_SRC  

 #+BEGIN_SRC ipython :session s
   import multiprocessing
   from gensim.models.doc2vec import Doc2Vec, TaggedDocument
   cores = multiprocessing.cpu_count()
   size = 100
   docs = [TaggedDocument(doc, [tag]) for tag, doc in enumerate(X)]
   d2v = Doc2Vec(
       docs,
       vector_size=size,
       window=10,
       min_count=2,
       workers=cores,
       hs=0,
       sample=0,
       alpha=0.05)
   d2v.train(docs, total_examples=len(docs), epochs=10)
 #+END_SRC

** Embeddings with FastText
   #+BEGIN_SRC ipython :session s
     min_len = 2
     def tokenize(phrase):
	 return [w.lower() for w in phrase.split() 
		 if w.isalpha()
		 and len(w) >= min_len]
   #+END_SRC

   #+RESULTS:
   : # Out[123]:

   #+BEGIN_SRC ipython :session s
     from gensim.models import FastText
     vocabulary = train_X.apply(tokenize)
     ft = FastText(vocabulary, size=200, window=6, min_count=min_len, iter=10)
     fname = "./toxic/fasttext.model"
     ft.save(fname)
   #+END_SRC

   #+RESULTS:
   : # Out[105]:

** Classification with LSTM Network
   #+BEGIN_SRC ipython :session s
     from gensim.models import FastText
     from keras.models import Sequential
     from keras.layers import Dense, LSTM

     tags = ['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] 
     #ft = FastText.load("./toxic/fasttext.model")


     def mean_vector_embed(phrases):
	 token_lists = phrases.apply(tokenize)
	 non_empty_token_lists = token_lists[token_lists.transform(lambda x: len(x) > 0)]
	 word_vectors = [np.mean(ft.wv[ts], axis=1) for ts in non_empty_token_lists]
	 return word_vectors

     input_vectors = mean_vector_embed(train_X)
     labels = train_Y
     m = Sequential()
     m.add(LSTM(50))
     m.add(Dense(len(tags), activation='softmax'))
     m.compile(loss='categorical_crossentropy', 
	       optimizer='adam', 
	       metrics=['accuracy'])

     m.fit(input_vectors, labels, epochs=3, batch_size=64)
     scores = m.evaluate(test_X, test_y, verbose=0)
     print("Accuracy: %.2f%" % (scores[1]))
  #+END_SRC
